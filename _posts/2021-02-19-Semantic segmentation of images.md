---
layout: post
title: å›¾åƒçš„è¯­ä¹‰åˆ†å‰²
date: 2021-02-19
author: Bend
header-img: img/post-bg-seg.png
catalog: true
tags:
- U-Net
- Tensorflow
---

å›¾åƒçš„è¯­ä¹‰åˆ†å‰²ç®€å•æ¥è¯´å°±æ˜¯å¯¹äºå›¾åƒçš„æ¯ä¸€ä¸ªåƒç´ ï¼Œéƒ½ç»™å‡ºå¯¹åº”çš„ç±»åˆ«ï¼Œä»è€Œå®ç°åƒç´ çº§åˆ«çš„åˆ†ç±»ã€‚

## è¿è¡Œç¯å¢ƒ

tensorflow2.0.0

## [[æ•°æ®é›†]] ä»‹ç»

[[Cityscapes]] æ•°æ®é›†

ç²¾ç»†æ³¨é‡Šæ•°æ®é›†åŒ…å« 2975 å¼ è®­ç»ƒå›¾ç‰‡å’Œ 500 å¼ éªŒè¯å›¾ç‰‡ã€‚åŒ…å«äº†è¡—æ™¯å›¾ç‰‡å’Œå¯¹åº”çš„æ ‡ç­¾ï¼Œæ ‡ç­¾å…± 34 ç±»ã€‚

æ•°æ®é›†åŒ…å«ä¸¤éƒ¨åˆ† leftImg8bit å’Œ gtFine æ–‡ä»¶å¤¹ï¼ŒleftImg8bit ä¸ºåŸå§‹å›¾ç‰‡ï¼ŒgtFine ä¸ºå¯¹åº”æ ‡ç­¾
Images å›¾åƒå¤§å° ä¸º 2048*1024ï¼Œ
gtFine æ˜¯å›¾åƒçš„åˆ†å‰²å›¾

## [[U-Net]] æ¨¡å‹

### U-Net ç®€ä»‹

U-Net æ˜¯ä¸€ä¸ªéå¸¸çŸ¥åçš„ç”¨æ¥è¿›è¡Œå›¾åƒè¯­ä¹‰åˆ†å‰²çš„æ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œï¼Œåˆšå¼€å§‹ä¸»è¦æ˜¯åº”ç”¨äºåŒ»å­¦å›¾åƒå¤„ç†æ–¹é¢

U-Net å’Œ FCN éå¸¸çš„ç›¸ä¼¼ï¼ŒU-Net æ¯” FCN ç¨æ™šæå‡ºæ¥ï¼Œä½†éƒ½å‘è¡¨åœ¨ 2015 å¹´ï¼Œå’Œ FCN ç›¸æ¯”ï¼ŒU-Net çš„ç¬¬ä¸€ä¸ªç‰¹ç‚¹æ˜¯å®Œå…¨å¯¹ç§°ï¼Œä¹Ÿå°±æ˜¯å·¦è¾¹å’Œå³è¾¹æ˜¯å¾ˆç±»ä¼¼çš„ï¼Œè€Œ FCN çš„ decoder ç›¸å¯¹ç®€å•ï¼Œåªç”¨äº†ä¸€ä¸ª deconvolution çš„æ“ä½œï¼Œä¹‹åå¹¶æ²¡æœ‰è·Ÿä¸Šå·ç§¯ç»“æ„ã€‚

ç¬¬äºŒä¸ªåŒºåˆ«å°±æ˜¯ skip connectionï¼ŒFCN ç”¨çš„æ˜¯åŠ æ“ä½œï¼ˆsummationï¼‰ï¼ŒU-Net ç”¨çš„æ˜¯å æ“ä½œï¼ˆconcatenationï¼‰ã€‚è¿™äº›éƒ½æ˜¯ç»†èŠ‚ï¼Œé‡ç‚¹æ˜¯å®ƒä»¬çš„ç»“æ„ç”¨äº†ä¸€ä¸ªæ¯”è¾ƒç»å…¸çš„æ€è·¯ï¼Œä¹Ÿå°±æ˜¯ç¼–ç å’Œè§£ç ï¼ˆencoder-decoderï¼‰ï¼Œæ—©åœ¨ 2006 å¹´å°±è¢« Hinton å¤§ç¥æå‡ºæ¥å‘è¡¨åœ¨äº† nature ä¸Š.

### U-Net ç½‘ç»œç»“æ„

![](https://cdn.bend1031.top/img/image-20210219103425041.png)

æ•´ä¸ª U-Net ç½‘ç»œç»“æ„å¦‚å›¾ ï¼Œç±»ä¼¼äºä¸€ä¸ªå¤§å¤§çš„ U å­—æ¯ï¼šé¦–å…ˆè¿›è¡Œ Conv+Pooling ä¸‹é‡‡æ ·ï¼›ç„¶å Deconv åå·ç§¯è¿›è¡Œä¸Šé‡‡æ ·ï¼Œcrop ä¹‹å‰çš„ä½å±‚ feature mapï¼Œè¿›è¡Œèåˆï¼›ç„¶åå†æ¬¡ä¸Šé‡‡æ ·ã€‚é‡å¤è¿™ä¸ªè¿‡ç¨‹ï¼Œç›´åˆ°è·å¾—è¾“å‡º 388x388x2 çš„ feature mapï¼Œæœ€åç»è¿‡ softmax è·å¾— output segment mapã€‚æ€»ä½“æ¥è¯´ä¸ FCN æ€è·¯éå¸¸ç±»ä¼¼ã€‚

### U-Net ç‰¹ç‚¹

åœ¨å°æ•°æ®é›†ä¸Šè¡¨ç°è‰¯å¥½
ä½¿ç”¨ tf.concat è¿›è¡Œå åŠ ï¼Œä¸ [[FCN]] çš„ tf.add æœ‰åŒºåˆ«

## Tensorflow ä»£ç 

### å¯¼å…¥åŒ…

```python
import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np
import os
import glob
```

### åŠ è½½æ‰“ä¹±è®­ç»ƒé›†

é¦–å…ˆå°†éœ€è¦è®­ç»ƒä¸éªŒè¯çš„å›¾ç‰‡è·¯å¾„éƒ½åŠ è½½è¿›æ¥

```python
# è·å–æ•°æ®è·¯å¾„åˆ—è¡¨ 2975 å¼ è®­ç»ƒå›¾ç‰‡
# å›¾ç‰‡å¤§å° 1024*2048
img = glob.glob (r"./dataset/leftImg8bit/train/*/*.png")
train_count = len (img)
# æ ‡æ³¨åˆ—è¡¨
label = glob.glob (r"./dataset/gtFine/train/*/*_gtFine_labelIds.png")


# æµ‹è¯•é›†å›¾ç‰‡ 500 å¼ 
img_val = glob.glob (r"./dataset/leftImg8bit/val/*/*.png")
label_val = glob.glob (r"./dataset/gtFine/val/*/*_gtFine_labelIds.png")
test_count = len (img_val)

# å°†è®­ç»ƒå›¾ç‰‡æ‰“ä¹±
np.random.seed (2019)
# åˆ›å»ºé•¿åº¦ä¸º image å›¾ç‰‡æ•°é‡çš„ä¹±åºåˆ—è¡¨
index = np.random.permutation (len (img))
img = np.array (img)[index]
label = np.array (label)[index]
```

### å®šä¹‰åŠ è½½å˜æ¢å‡½æ•°

å°†å›¾ç‰‡è½¬ä¸º tensor ç±»å‹ï¼Œå¹¶ä¸”ä¸”è¿›è¡Œæ•°æ®å¢å¼ºï¼Œå¼•å…¥éšæœºè£å‰ªä¸ç¿»è½¬

```python
def read_png_image (path):
    # è®­ç»ƒé›†å›¾ç‰‡ä¸ºå½©è‰²å›¾ç‰‡ channel ä¸º 3
    img = tf.io.read_file (path)

    img = tf.image.decode_png (img, channels=3)
    return img


def read_png_label (path):
    # éªŒè¯é›†å›¾ç‰‡ä¸ºç°åº¦å›¾ç‰‡ channel ä¸º 1
    img = tf.io.read_file (path)
    img = tf.image.decode_png (img, channels=1)
    return img


def crop_img (img, label):
    """ å›¾ç‰‡éšæœºè£å‰ª

    å°† img ä¸ label é€šé“åˆå¹¶ï¼Œç„¶åç¼©æ”¾ï¼Œå†è¿›è¡Œéšæœºåˆ†å‰²
    """
    # [1024,2048,3]+[1024,2048,1]-> [1024,2048,4] åˆå¹¶
    concat_img = tf.concat ([img, label], axis=-1)

    # ç¼©æ”¾ [1024,2048,4]-> [280,280,4]
    concat_img = tf.image.resize (
        concat_img, (280, 280), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)

    # éšæœºè£å‰ª [280,280,4]-> [256,256,4]
    crop_img = tf.image.random_crop (concat_img, size=[256, 256, 4])

    # åˆ†å‰²å›æ¥
    img, label = tf.split (
        crop_img, axis=-1, num_or_size_splits=[3, 1])
    return img, label


def normal_img (img, label):
    """ å›¾ç‰‡å½’ä¸€åŒ–
    """
    img = tf.cast (img, tf.float32)
    label = tf.cast (label, tf.int32)
    img = img / 127.5 - 1  # å½’ä¸€åŒ–åˆ° [-1,1]
    return img, label


def load_train (img_path, label_path):
    """ åŠ è½½è®­ç»ƒé›†

    å¼•å…¥éšæœºç¿»è½¬
    """
    # è¯»å–
    img = read_png_image (img_path)
    label = read_png_label (label_path)

    # è£å‰ª
    img, label = crop_img (img, label)

    # éšæœºç¿»è½¬
    if tf.random.uniform (()) > 0.5:
        img = tf.image.flip_left_right (img)
        label = tf.image.flip_left_right (label)

    return normal_img (img, label)


def load_val (img_path, label_path):
    """ åŠ è½½éªŒè¯é›†

    ä¸éœ€è¦åšè£å‰ªä½†éœ€è¦åš resize åˆ° [256,256]
    """
    img = read_png_image (img_path)
    label = read_png_label (label_path)
    img = tf.image.resize (img, (256, 256))
    label = tf.image.resize (label, (256, 256))

    return normal_img (img, label)
```

### æ•°æ®é›†é…ç½®

```python
EPOCHS = 60
BATCH_SIZE = 32
BUFFER_SIZE = 300
# æ•°æ®åº“è¿­ä»£ä¸€æ¬¡éœ€è¦çš„ step æ•°
steps_per_epoch = train_count // BATCH_SIZE
val_step = test_count // BATCH_SIZE


dataset_train = tf.data.Dataset.from_tensor_slices ((img, label))
dataset_val = tf.data.Dataset.from_tensor_slices ((img_val, label_val))


AUTOTUNE = tf.data.experimental.AUTOTUNE
dataset_train = dataset_train.map (
    load_train, num_parallel_calls=AUTOTUNE)  # å¤šçº¿ç¨‹è‡ªåŠ¨åˆ¤æ–­
dataset_val = dataset_val.map (
    load_val, num_parallel_calls=AUTOTUNE)  # å¤šçº¿ç¨‹è‡ªåŠ¨åˆ¤æ–­

# %% æ•°æ®é›†é…ç½®
# prefetch ()ï¼šGPU ç»ƒæ—¶ CPU ç»§ç»­è¯»å–
dataset_train = dataset_train.cache ().repeat ().shuffle (
    BUFFER_SIZE).batch (BATCH_SIZE).prefetch (AUTOTUNE)

dataset_val = dataset_val.cache ().batch (BATCH_SIZE)
```

### åˆ›å»ºæ¨¡å‹

å¯¹ç…§ U-Net æ¨¡å‹æ­å»ºç½‘ç»œï¼Œä¸ºäº†å›¾ç‰‡å¤§å°åœ¨å·ç§¯è¿‡ç¨‹ä¸­ä¿æŒä¸å˜ï¼Œéœ€è¦è¿›è¡Œé›¶å¡«å……

```python
def create_model ():
   inputs = tf.keras.layers.Input (shape=(256, 256, 3))

   # ä¸‹é‡‡æ ·éƒ¨åˆ†
   # [256,256,3]-> [256,256,64]
   x = tf.keras.layers.Conv2D (
       64, 3, padding="same", activation="relu")(inputs)
   x = tf.keras.layers.BatchNormalization ()(x)
   x = tf.keras.layers.Conv2D (64, 3, padding="same", activation="relu")(x)
   x = tf.keras.layers.BatchNormalization ()(x)

   # [256,256,64]-> [128,128,64]
   x1 = tf.keras.layers.MaxPooling2D (padding="same")(x)
   # [128,128,64]-> [128,128,128]
   x1 = tf.keras.layers.Conv2D (128, 3, padding="same", activation="relu")(x1)
   x1 = tf.keras.layers.BatchNormalization ()(x1)
   x1 = tf.keras.layers.Conv2D (128, 3, padding="same", activation="relu")(x1)
   x1 = tf.keras.layers.BatchNormalization ()(x1)

   # [128,128,128]-> [64,64,128]
   x2 = tf.keras.layers.MaxPooling2D (padding="same")(x1)
   # [64,64,128]-> [64,64,256]
   x2 = tf.keras.layers.Conv2D (256, 3, padding="same", activation="relu")(x2)
   x2 = tf.keras.layers.BatchNormalization ()(x2)
   x2 = tf.keras.layers.Conv2D (256, 3, padding="same", activation="relu")(x2)
   x2 = tf.keras.layers.BatchNormalization ()(x2)

   # [64,64,256]-> [64,64,512]
   x3 = tf.keras.layers.MaxPooling2D (padding="same")(x2)
   # [64,64,512]-> [32,32,512]
   x3 = tf.keras.layers.Conv2D (512, 3, padding="same", activation="relu")(x3)
   x3 = tf.keras.layers.BatchNormalization ()(x3)
   x3 = tf.keras.layers.Conv2D (512, 3, padding="same", activation="relu")(x3)
   x3 = tf.keras.layers.BatchNormalization ()(x3)

   # [32,32,512]-> [16,16,512]
   x4 = tf.keras.layers.MaxPooling2D (padding="same")(x3)
   # [16,16,512]-> [16,16,1024]
   x4 = tf.keras.layers.Conv2D (1024, 3, padding="same", activation="relu")(x4)
   x4 = tf.keras.layers.BatchNormalization ()(x4)
   x4 = tf.keras.layers.Conv2D (1024, 3, padding="same", activation="relu")(x4)
   x4 = tf.keras.layers.BatchNormalization ()(x4)

   # ä¸Šé‡‡æ ·éƒ¨åˆ†
   # [16,16,1024]-> [32,32,512] strides=2: æ”¾å¤§ä¸¤å€
   x5 = tf.keras.layers.Conv2DTranspose (
       512, 2, strides=2, padding="same", activation="relu")(x4)
   x5 = tf.keras.layers.BatchNormalization ()(x5)

   # [32,32,512]+[32,32,512]-> [32,32,1024]
   x6 = tf.concat ([x3, x5], axis=-1)
   # [32,32,1024]-> [32,32,512]
   x6 = tf.keras.layers.Conv2D (512, 3, padding="same", activation="relu")(x6)
   x6 = tf.keras.layers.BatchNormalization ()(x6)
   x6 = tf.keras.layers.Conv2D (512, 3, padding="same", activation="relu")(x6)
   x6 = tf.keras.layers.BatchNormalization ()(x6)

   # [32,32,512]-> [64,64,256]
   x7 = tf.keras.layers.Conv2DTranspose (
       256, 2, strides=2, padding="same", activation="relu")(x6)
   x7 = tf.keras.layers.BatchNormalization ()(x7)

   # [64,64,256]+[64,64,256]-> [64,64,512]
   x8 = tf.concat ([x2, x7], axis=-1)
   # [64,64,512]-> [64,64,256]
   x8 = tf.keras.layers.Conv2D (256, 3, padding="same", activation="relu")(x8)
   x8 = tf.keras.layers.BatchNormalization ()(x8)
   x8 = tf.keras.layers.Conv2D (256, 3, padding="same", activation="relu")(x8)
   x8 = tf.keras.layers.BatchNormalization ()(x8)

   # [64,64,256]-> [128,128,128]
   x9 = tf.keras.layers.Conv2DTranspose (
       128, 2, strides=2, padding="same", activation="relu")(x8)
   x9 = tf.keras.layers.BatchNormalization ()(x9)

   # [128,128,128]+[128,128,128]-> [128,128,256]
   x10 = tf.concat ([x1, x9], axis=-1)
   # [128,128,256]-> [128,128,128]
   x10 = tf.keras.layers.Conv2D (
       128, 3, padding="same", activation="relu")(x10)
   x10 = tf.keras.layers.BatchNormalization ()(x10)
   x10 = tf.keras.layers.Conv2D (
       128, 3, padding="same", activation="relu")(x10)
   x10 = tf.keras.layers.BatchNormalization ()(x10)

   # [128,128,128]-> [256,256,64]
   x11 = tf.keras.layers.Conv2DTranspose (
       64, 2, strides=2, padding="same", activation="relu")(x10)
   x11 = tf.keras.layers.BatchNormalization ()(x11)

   # [256,256,64]+[256,256,64]-> [256,256,128]
   x12 = tf.concat ([x, x11], axis=-1)
   # [256,256,128]-> [256,256,64]
   x12 = tf.keras.layers.Conv2D (64, 3, padding="same", activation="relu")(x12)
   x12 = tf.keras.layers.BatchNormalization ()(x12)
   x12 = tf.keras.layers.Conv2D (
       64, 3, padding="same", activation="relu")(x12)
   x12 = tf.keras.layers.BatchNormalization ()(x12)

   # è¾“å‡ºå±‚ [256,256,64]-> [256,256,34]
   output = tf.keras.layers.Conv2D (
       34, 1, padding="same", activation="softmax")(x12)
   return tf.keras.Model (inputs=inputs, outputs=output)

```

### é…ç½®æ¨¡å‹

```python
# %% é…ç½®æ¨¡å‹
model = create_model ()
model.summary () # æ‰“å°ç½‘ç»œç»“æ„
# tf.keras.utils.plot_model (model)

checkpoint_save_path = "./checkpoint/unet.ckpt"
if os.path.exists (checkpoint_save_path + '.index'):  # åˆ¤æ–­å½“å‰æ–­ç‚¹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    print ('-------------load the model-----------------')
    model.load_weights (checkpoint_save_path)

cp_callback = tf.keras.callbacks.ModelCheckpoint (filepath=checkpoint_save_path,
                                                 save_weights_only=True,
                                                 save_best_only=True)
```

é…ç½®ä¼˜åŒ–å™¨ä¸º Adamï¼ŒæŸå¤±å‡½æ•°ä¸ºäº¤å‰ç†µï¼Œç”±äºè¾“å‡ºä¸ºå…·ä½“çš„æ•°å€¼å¤§å°ï¼ŒæŒ‡æ ‡é€‰ä¸º accï¼ŒåŒæ—¶ç”±äºåœ¨ä¸€èˆ¬çš„è¯­ä¹‰åˆ†å‰²è¯„ä»·æŒ‡æ ‡ä¸­ï¼ŒIoU ç»å¸¸ç”¨åˆ°ï¼Œä½†æ˜¯éœ€è¦ç»è¿‡ one_hot ç¼–ç ï¼Œæ‰€ä»¥éœ€è¦è‡ªå·±é‡å†™ IoU

```python
model.compile (optimizer=tf.keras.optimizers.Adam (learning_rate=0.001),
              loss="sparse_categorical_crossentropy",
              metrics=["acc", MeanIoU (num_classes=34)]
              )
class MeanIoU (tf.keras.metrics.MeanIoU):
    def __call__(self, y_true, y_pred, sample_weight=None):
        y_pred = tf.argmax (y_pred, axis=-1)
        return super ().__call__(y_true, y_pred, sample_weight=sample_weight)

```

### æ¨¡å‹è®­ç»ƒ

```python
# %% æ¨¡å‹è®­ç»ƒ
history = model.fit (dataset_train,
                    epochs=3,
                    steps_per_epoch=steps_per_epoch,
                    validation_data=dataset_val,
                    validation_steps=val_step)

```

## ç»“å°¾

ç”±äº U-Net ç½‘ç»œä¸­æœ‰ç»´åº¦æ‹¼æ¥ï¼Œå¯¹æ˜¾å¡æ˜¾å­˜å ç”¨è¾ƒå¤šï¼Œåœ¨å®é™…è®­ç»ƒè¿‡ç¨‹ä¸­æˆ‘è¿™å°ç”µè„‘è·‘ä¸å¤ªåŠ¨ï¼Œè®­ç»ƒé€Ÿåº¦æ¯”è¾ƒç¼“æ…¢ğŸ˜‚
